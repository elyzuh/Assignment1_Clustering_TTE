{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "Assignment 1 for Clustering:\n",
    "New and novel methods in Machine Learning are made either by borrowing formulas and concepts from other scientific fields and redefining it based on new sets of assumptions, or by adding an extra step to an already existing framework of methodology.\n",
    "\n",
    "In this exercise (Assignment 1 of the Clustering Topic), we will try to develop a novel method of Target Trial Emulation by integrating concepts of Clustering into the already existing framework. Target Trial Emulation is a new methodological framework in epidemiology which tries to account for the biases in old and traditional designs.\n",
    "\n",
    "These are the instructions:\n",
    "1. Look at this website: https://rpubs.com/alanyang0924/TTE\n",
    "2. Extract the dummy data in the package and save it as \"data_censored.csv\"\n",
    "2. Convert the R codes into Python Codes (use Jupyter Notebook), replicate the results using your python code.\n",
    "3. Create another copy of your Python Codes, name it TTE-v2 (use Jupyter Notebook).\n",
    "4. Using TTE-v2, think of a creative way on where you would integrate a clustering mechanism, understand each step carefully and decide at which step a clustering method can be implemented. Generate insights from your results.\n",
    "5. Do this by pair, preferably your thesis partner.\n",
    "6. Push to your github repository.\n",
    "7. Deadline is 2 weeks from today: February 28, 2025 at 11:59 pm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview:\n",
    "\n",
    "1. Setup\n",
    "2. Data Preparation\n",
    "3. Weight models and censoring\n",
    "    (3.1) Censoring due to treatment switching\n",
    "    (3.2) Other informative censoring\n",
    "4. Calculate weights\n",
    "5. Specify outcome models\n",
    "6. Expand Trials\n",
    "    (6.1) Create Sequence of Trials Data\n",
    "7. Load or Sample from Expanded Data\n",
    "8. Fit Marginal Structural Model\n",
    "9. Inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import resample\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "A sequence of target trials analysis starts by specifying which estimand will be used:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define estimands\n",
    "trial_pp = {\"estimand\": \"PP\"}  # Per-protocol\n",
    "trial_itt = {\"estimand\": \"ITT\"}  # Intention-to-treat\n",
    "\n",
    "# Create directories for saving files\n",
    "trial_pp_dir = os.path.join(os.getcwd(), \"trial_pp\")\n",
    "os.makedirs(trial_pp_dir, exist_ok=True)\n",
    "\n",
    "trial_itt_dir = os.path.join(os.getcwd(), \"trial_itt\")\n",
    "os.makedirs(trial_itt_dir, exist_ok=True)\n",
    "\n",
    "# Store directories in the trial objects\n",
    "trial_pp[\"directory\"] = trial_pp_dir\n",
    "trial_itt[\"directory\"] = trial_itt_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, is it useful to create a directory to save files for later inspection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Preparation\n",
    "\n",
    "Next the user must specify the observational input data that will be used for the target trial emulation. Here we need to specify which columns contain which values and how they should be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  period  treatment  x1        x2  x3        x4  age     age_s  outcome  \\\n",
      "0   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "1   1       1          1   1  0.002200   0  0.734203   37  0.166667        0   \n",
      "2   1       2          1   0 -0.481762   0  0.734203   38  0.250000        0   \n",
      "3   1       3          1   0  0.007872   0  0.734203   39  0.333333        0   \n",
      "4   1       4          1   1  0.216054   0  0.734203   40  0.416667        0   \n",
      "\n",
      "   censored  eligible  \n",
      "0         0         1  \n",
      "1         0         0  \n",
      "2         0         0  \n",
      "3         0         0  \n",
      "4         0         0  \n"
     ]
    }
   ],
   "source": [
    "data_censored = pd.read_csv(\"data_censored.csv\")\n",
    "\n",
    "# Display the first few rows\n",
    "print(data_censored.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data':      id  period  treatment  x1        x2  x3        x4  age     age_s  \\\n",
      "0     1       0          1   1  1.146148   0  0.734203   36  0.083333   \n",
      "1     1       1          1   1  0.002200   0  0.734203   37  0.166667   \n",
      "2     1       2          1   0 -0.481762   0  0.734203   38  0.250000   \n",
      "3     1       3          1   0  0.007872   0  0.734203   39  0.333333   \n",
      "4     1       4          1   1  0.216054   0  0.734203   40  0.416667   \n",
      "..   ..     ...        ...  ..       ...  ..       ...  ...       ...   \n",
      "720  99       3          0   0 -0.747906   1  0.575268   68  2.750000   \n",
      "721  99       4          0   0 -0.790056   1  0.575268   69  2.833333   \n",
      "722  99       5          1   1  0.387429   1  0.575268   70  2.916667   \n",
      "723  99       6          1   1 -0.033762   1  0.575268   71  3.000000   \n",
      "724  99       7          0   0 -1.340497   1  0.575268   72  3.083333   \n",
      "\n",
      "     outcome  censored  eligible  \n",
      "0          0         0         1  \n",
      "1          0         0         0  \n",
      "2          0         0         0  \n",
      "3          0         0         0  \n",
      "4          0         0         0  \n",
      "..       ...       ...       ...  \n",
      "720        0         0         0  \n",
      "721        0         0         0  \n",
      "722        0         0         0  \n",
      "723        0         0         0  \n",
      "724        1         0         0  \n",
      "\n",
      "[725 rows x 12 columns], 'id': 'id', 'period': 'period', 'treatment': 'treatment', 'outcome': 'outcome', 'eligible': 'eligible'}\n"
     ]
    }
   ],
   "source": [
    "# Define a function to structure the data\n",
    "def set_data(data, id_col, period_col, treatment_col, outcome_col, eligible_col):\n",
    "    return {\n",
    "        \"data\": data,\n",
    "        \"id\": id_col,\n",
    "        \"period\": period_col,\n",
    "        \"treatment\": treatment_col,\n",
    "        \"outcome\": outcome_col,\n",
    "        \"eligible\": eligible_col,\n",
    "    }\n",
    "\n",
    "# Using the function\n",
    "trial_pp_data = set_data(\n",
    "    data=data_censored,\n",
    "    id_col=\"id\",\n",
    "    period_col=\"period\",\n",
    "    treatment_col=\"treatment\",\n",
    "    outcome_col=\"outcome\",\n",
    "    eligible_col=\"eligible\",\n",
    ")\n",
    "\n",
    "# ITT (without pipe equivalent)\n",
    "trial_itt_data = set_data(\n",
    "    data=data_censored,\n",
    "    id_col=\"id\",\n",
    "    period_col=\"period\",\n",
    "    treatment_col=\"treatment\",\n",
    "    outcome_col=\"outcome\",\n",
    "    eligible_col=\"eligible\",\n",
    ")\n",
    "\n",
    "# Print the result (optional)\n",
    "print(trial_itt_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Weight models and censoring\n",
    "\n",
    "- To adjust for the effects of informative censoring, inverse probability of censoring weights (IPCW) can be applied. \n",
    "- To estimate these weights, we construct time-to-(censoring) event models.\n",
    "- Two sets of models are fit for the two censoring mechanisms which may apply: censoring due to deviation from assigned treatment and other informative censoring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Censoring due to treatment switching\n",
    "\n",
    "We specify model formulas to be used for calculating the probability of receiving treatment in the current period. Separate models are fitted for patients who had treatment = 1 and those who had treatment = 0 in the previous period. Stabilized weights are used by fitting numerator and denominator models.\n",
    "\n",
    "There are optional arguments to specify columns which can include/exclude observations from the treatment models. These are used in case it is not possible for a patient to deviate from a certain treatment assignment in that period.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'numerator': 'treatment ~ age', 'denominator': 'treatment ~ age + x1 + x3', 'model_fitter': 'te_stats_glm_logit', 'fitted_model': LogisticRegression()}\n"
     ]
    }
   ],
   "source": [
    "class Trial:\n",
    "    def __init__(self, data, estimand, directory):\n",
    "        self.data = data[\"data\"]  # Extract the DataFrame from the dictionary\n",
    "        self.estimand = estimand\n",
    "        self.directory = directory  # Store the directory path\n",
    "        self.switch_weights = None\n",
    "        self.censor_weights = None\n",
    "\n",
    "    def fit_logistic_regression(self, X, y, save_path):\n",
    "        \"\"\"Fits a logistic regression model and saves it to a file.\"\"\"\n",
    "        if len(np.unique(y)) < 2:\n",
    "            print(\"Skipping logistic regression: Only one class present in y\")\n",
    "            return None\n",
    "        model = LogisticRegression()\n",
    "        model.fit(X, y)\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        with open(save_path, \"wb\") as f:\n",
    "            pickle.dump(model, f)\n",
    "        return model\n",
    "    \n",
    "    def set_censor_weight_model(self, censor_event, numerator=\"1\", denominator=\"1\", pool_models=\"none\", model_fitter=None):\n",
    "        if model_fitter is None: \n",
    "            model_fitter = self.fit_logistic_regression\n",
    "            \n",
    "        if censor_event not in self.data.columns:\n",
    "            raise ValueError(f\"'{censor_event}' must be a column in the dataset.\")\n",
    "        \n",
    "        formula_numerator = f\"1 - {censor_event} ~ {numerator}\"\n",
    "        formula_denominator = f\"1 - {censor_event} ~ {denominator}\"\n",
    "\n",
    "        self.censor_weights = {\n",
    "            \"numerator\": formula_numerator,\n",
    "            \"denominator\": formula_denominator,\n",
    "            \"pool_numerator\": pool_models in [\"numerator\", \"both\"],\n",
    "            \"pool_denominator\": pool_models == \"both\",\n",
    "            \"model_fitter\": \"te_stats_glm_logit\"\n",
    "        }\n",
    "\n",
    "        self.censor_weights[\"fitted_model\"] = model_fitter(self.data[numerator.split(\" + \")], self.data[censor_event], os.path.join(self.directory, \"censor_models\", \"censor_model.pkl\"))\n",
    "        return self\n",
    "\n",
    "    def set_switch_weight_model(self, numerator=None, denominator=None, model_fitter=None, eligible_wts_0=None, eligible_wts_1=None):\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"set_data() before setting switch weight models\")\n",
    "        \n",
    "        if self.estimand == \"ITT\":\n",
    "            raise ValueError(\"Switching weights are not supported for intention-to-treat analyses\")\n",
    "\n",
    "        if eligible_wts_0 and eligible_wts_0 in self.data.columns:\n",
    "            self.data = self.data.rename(columns={eligible_wts_0: \"eligible_wts_0\"})\n",
    "        if eligible_wts_1 and eligible_wts_1 in self.data.columns:\n",
    "            self.data = self.data.rename(columns={eligible_wts_1: \"eligible_wts_1\"})\n",
    "\n",
    "        if numerator is None:\n",
    "            numerator = \"1\"\n",
    "        if denominator is None:\n",
    "            denominator = \"1\"\n",
    "        \n",
    "        if \"time_on_regime\" in denominator:\n",
    "            raise ValueError(\"time_on_regime should not be used in denominator.\")\n",
    "\n",
    "        formula_numerator = f\"treatment ~ {numerator}\"\n",
    "        formula_denominator = f\"treatment ~ {denominator}\"\n",
    "\n",
    "        self.switch_weights = {\n",
    "            \"numerator\": formula_numerator,\n",
    "            \"denominator\": formula_denominator,\n",
    "            \"model_fitter\": \"te_stats_glm_logit\",\n",
    "        }\n",
    "\n",
    "        if model_fitter is not None:\n",
    "            fitted_model = model_fitter(self.data[numerator.split(\" + \")], self.data['treatment'], os.path.join(self.directory, \"switch_models\", \"numerator.pkl\"))\n",
    "            self.switch_weights[\"fitted_model\"] = fitted_model \n",
    "\n",
    "    def show_switch_weights(self):\n",
    "        return self.switch_weights if self.switch_weights else \"Not calculated\"\n",
    "    \n",
    "    def show_censor_weights(self):\n",
    "        return self.censor_weights if self.censor_weights else \"Not calculated\"\n",
    "    \n",
    "trial_pp.set_switch_weight_model(numerator='age', denominator='age + x1 + x3', model_fitter=trial_pp.fit_logistic_regression)\n",
    "print(trial_pp.show_switch_weights())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'numerator': '1 - censored ~ x2', 'denominator': '1 - censored ~ x2 + x1', 'pool_numerator': False, 'pool_denominator': False, 'model_fitter': 'te_stats_glm_logit', 'fitted_model': LogisticRegression()}\n",
      "{'numerator': '1 - censored ~ x2', 'denominator': '1 - censored ~ x2 + x1', 'pool_numerator': True, 'pool_denominator': False, 'model_fitter': 'te_stats_glm_logit', 'fitted_model': LogisticRegression()}\n"
     ]
    }
   ],
   "source": [
    "# 3.2 \n",
    "# Initialize trial object\n",
    "trial_pp = Trial(trial_pp_data, \"PP\", trial_pp_dir)\n",
    "\n",
    "# Set censor weight model for PP\n",
    "trial_pp.set_censor_weight_model(\n",
    "    censor_event=\"censored\", \n",
    "    numerator=\"x2\", \n",
    "    denominator=\"x2 + x1\", \n",
    "    pool_models=\"none\", \n",
    "    model_fitter=lambda X, y, path: trial_pp.fit_logistic_regression(X, y, os.path.join(trial_pp_dir, \"censor_models\", \"censor_model.pkl\"))\n",
    ")\n",
    "\n",
    "print(trial_pp.show_censor_weights())\n",
    "\n",
    "# Initialize trial object for ITT\n",
    "trial_itt = Trial(trial_itt_data, \"ITT\", trial_itt_dir)\n",
    "\n",
    "# Set censor weight model for ITT\n",
    "trial_itt.set_censor_weight_model(\n",
    "    censor_event=\"censored\", \n",
    "    numerator=\"x2\", \n",
    "    denominator=\"x2 + x1\", \n",
    "    pool_models=\"numerator\",  # Pool numerator across treatment arms\n",
    "    model_fitter=lambda X, y, path: trial_itt.fit_logistic_regression(X, y, os.path.join(trial_itt_dir, \"censor_models\", \"censor_model.pkl\"))\n",
    ")\n",
    "\n",
    "print(trial_itt.show_censor_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Calculate weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
